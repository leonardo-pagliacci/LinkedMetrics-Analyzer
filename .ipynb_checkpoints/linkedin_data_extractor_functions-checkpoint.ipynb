{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41e7ec9",
   "metadata": {},
   "source": [
    "## Linkedin API\n",
    "https://github.com/tomquirk/linkedin-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5b3f26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChallengeException",
     "evalue": "CHALLENGE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mChallengeException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlinkedin_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linkedin\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Authenticate using any Linkedin account credentials\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m api \u001b[38;5;241m=\u001b[39m Linkedin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/linkedin_api/linkedin.py:86\u001b[0m, in \u001b[0;36mLinkedin.__init__\u001b[0;34m(self, username, password, authenticate, refresh_cookies, debug, proxies, cookies, cookies_dir)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39m_set_session_cookies(cookies)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mauthenticate(username, password)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/linkedin_api/client.py:102\u001b[0m, in \u001b[0;36mClient.authenticate\u001b[0;34m(self, username, password)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_metadata()\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_authentication_request(username, password)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_metadata()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/linkedin_api/client.py:162\u001b[0m, in \u001b[0;36mClient._do_authentication_request\u001b[0;34m(self, username, password)\u001b[0m\n\u001b[1;32m    159\u001b[0m data \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogin_result\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPASS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChallengeException(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogin_result\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedException()\n",
      "\u001b[0;31mChallengeException\u001b[0m: CHALLENGE"
     ]
    }
   ],
   "source": [
    "from linkedin_api import Linkedin\n",
    "\n",
    "# Authenticate using any Linkedin account credentials\n",
    "api = Linkedin(\"--\", \"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907e66b",
   "metadata": {},
   "source": [
    "## Get profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0493d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def extract_linkedin_id(profile_url):\n",
    "    \"\"\"\n",
    "    Extracts the LinkedIn ID from a given profile URL, handling various URL formats.\n",
    "    \"\"\"\n",
    "    # Decode URL to handle any encoded characters\n",
    "    decoded_url = unquote(profile_url)\n",
    "    \n",
    "    # Parse the URL to get the path part\n",
    "    path = urlparse(decoded_url).path\n",
    "    \n",
    "    # Strip leading and trailing slashes then split by slashes\n",
    "    path_parts = path.strip(\"/\").split(\"/\")\n",
    "    \n",
    "    # LinkedIn ID is expected to be the last part of the path\n",
    "    linkedin_id = path_parts[-1]\n",
    "    \n",
    "    return linkedin_id\n",
    "\n",
    "def linkedin_profile_extractor(profile_url):\n",
    "    \"\"\"\n",
    "    Extracts and structures key information from a LinkedIn profile using its URL.\n",
    "\n",
    "    This function retrieves comprehensive details from a LinkedIn profile, including the user's\n",
    "    full name, professional headline, summary, industry, location, experience, education, languages,\n",
    "    projects, and skills. It is designed to parse the profile URL to extract the LinkedIn ID,\n",
    "    which is then used to fetch the profile data through API calls. The retrieved data is\n",
    "    structured into a readable and accessible format, suitable for various applications such as\n",
    "    professional networking, recruitment, and personal branding services.\n",
    "\n",
    "    Parameters:\n",
    "    - profile_url (str): The URL of the LinkedIn profile to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing structured information about the LinkedIn profile. This includes:\n",
    "        - 'fullName': The full name of the profile owner.\n",
    "        - 'headline': The professional headline.\n",
    "        - 'summary': A brief professional summary.\n",
    "        - 'industryName': The industry of the profile owner.\n",
    "        - 'locationName': The general location name.\n",
    "        - 'geoCountryName': The country name.\n",
    "        - 'geoLocationName': The specific geographical location.\n",
    "        - 'experience': A list of dictionaries, each representing a work experience entry.\n",
    "        - 'education': A list of dictionaries, each representing an education entry.\n",
    "        - 'languages': A list of languages listed on the profile.\n",
    "        - 'projects': A list of dictionaries, each representing a project entry.\n",
    "        - 'skills': A list of skills listed on the profile.\n",
    "        - 'profilePictureUrl': profile image url\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the LinkedIn ID from the URL using the refined extraction function\n",
    "    linkedin_id = extract_linkedin_id(profile_url)\n",
    "\n",
    "    # Use the API calls with the extracted LinkedIn ID\n",
    "    profile = api.get_profile(linkedin_id)\n",
    "\n",
    "    # Basic information extraction remains the same\n",
    "    extracted_info = {\n",
    "        'fullName': f\"{profile.get('firstName', '')} {profile.get('lastName', '')}\".strip(),\n",
    "        'headline': profile.get('headline', ''),\n",
    "        'summary': profile.get('summary', ''),\n",
    "        'industryName': profile.get('industryName', ''),\n",
    "        'locationName': profile.get('locationName', ''),\n",
    "        'geoCountryName': profile.get('geoCountryName', ''),\n",
    "        'geoLocationName': profile.get('geoLocationName', ''),\n",
    "        'experience': [],\n",
    "        'education': [],\n",
    "        'languages': profile.get('languages', 'No languages listed'),\n",
    "        'projects': [],\n",
    "        'skills': [],\n",
    "        'profilePictureUrl': None\n",
    "\n",
    "    }\n",
    "\n",
    "    # Streamline experience details\n",
    "    for exp in profile.get('experience', []):\n",
    "        experience_detail = {\n",
    "            'locationName': exp.get('locationName', ''),\n",
    "            'geoLocationName': exp.get('geoLocationName', ''),\n",
    "            'companyName': exp.get('companyName', ''),\n",
    "            'timePeriod': exp.get('timePeriod', {}),\n",
    "            'industries': exp.get('company', {}).get('industries', []),\n",
    "            'title': exp.get('title', '')\n",
    "        }\n",
    "        extracted_info['experience'].append(experience_detail)\n",
    "\n",
    "    # Streamline education details\n",
    "    for edu in profile.get('education', []):\n",
    "        education_detail = {\n",
    "            'schoolName': edu.get('schoolName', ''),\n",
    "            'timePeriod': edu.get('timePeriod', {}),\n",
    "            'degreeName': edu.get('degreeName', ''),\n",
    "            'fieldOfStudy': edu.get('fieldOfStudy', '')\n",
    "        }\n",
    "        extracted_info['education'].append(education_detail)\n",
    "        \n",
    "    # Streamline project details\n",
    "    projects_raw = profile.get('projects', [])\n",
    "    for project in projects_raw:\n",
    "        project_detail = {\n",
    "            'title': project.get('title', ''),\n",
    "            'timePeriod': project.get('timePeriod', {}),\n",
    "            'description': project.get('description', '')\n",
    "        }\n",
    "        extracted_info['projects'].append(project_detail)\n",
    "        \n",
    "    # Extract skills using the LinkedIn ID\n",
    "    skills = api.get_profile_skills(linkedin_id)\n",
    "    extracted_info['skills'] = [skill['name'] for skill in skills] if skills else 'No skills listed'\n",
    "    \n",
    "    # Extract the highest profile image resolution\n",
    "    if 'displayPictureUrl' in profile:\n",
    "        base_url = profile['displayPictureUrl']\n",
    "        # Directly check for the presence of each key in priority order\n",
    "        image_keys = ['img_800_800', 'img_400_400', 'img_200_200', 'img_100_100']\n",
    "        for key in image_keys:\n",
    "            if key in profile:\n",
    "                extracted_info['profilePictureUrl'] = base_url + profile[key]\n",
    "                break \n",
    "    \n",
    "    return extracted_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cda2d",
   "metadata": {},
   "source": [
    "## Get job description data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03f5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def extract_linkedin_job_id(job_url):\n",
    "    \n",
    "    decoded_url = unquote(job_url)\n",
    "    path = urlparse(decoded_url).path\n",
    "    path_parts = path.strip(\"/\").split(\"/\")\n",
    "    try:\n",
    "        view_index = path_parts.index(\"view\")\n",
    "        job_id = path_parts[view_index + 1] if len(path_parts) > view_index + 1 else None\n",
    "    except ValueError:\n",
    "        job_id = None\n",
    "        \n",
    "    return job_id\n",
    "\n",
    "def linkedin_job_description_extractor(job_url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts key information from a LinkedIn job posting based on the provided job URL. This function is designed\n",
    "    to simplify the process of retrieving job details by focusing on core aspects such as the job title, company name,\n",
    "    company URL, and a text description of the job.\n",
    "\n",
    "    Parameters:\n",
    "    - job_url (str): The URL of the LinkedIn job posting.\n",
    "\n",
    "    Returns:\n",
    "    - extracted_job_info (dict): A dictionary containing the extracted information from the job posting, including:\n",
    "        - 'title': The title of the job.\n",
    "        - 'companyName': The name of the company offering the job.\n",
    "        - 'companyURL': A URL to the company's LinkedIn page.\n",
    "        - 'descriptionText': The text description of the job, outlining responsibilities, requirements, and other job details.\n",
    "\n",
    "    The function assumes access to an API or mechanism (simulated here) that allows fetching detailed job information\n",
    "    using a job identifier extracted from the job URL. It structures the extracted information into a readable and\n",
    "    easily accessible format for further processing or analysis.\n",
    "\n",
    "    Usage:\n",
    "    This function can be particularly useful for job seekers, recruiters, or researchers interested in analyzing job\n",
    "    market trends, gathering information on specific job openings, or extracting data for job recommendation systems.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the LinkedIn Job ID from the URL\n",
    "    job_id = extract_linkedin_job_id(job_url)\n",
    "    \n",
    "    # Simulating fetching job details from LinkedIn API with job_id\n",
    "    job_description = api.get_job(job_id)  # This is a placeholder for the actual API call\n",
    "\n",
    "    # Accessing company details\n",
    "    company_details = job_description.get('companyDetails', {}).get('com.linkedin.voyager.deco.jobs.web.shared.WebCompactJobPostingCompany', {}).get('companyResolutionResult', {})\n",
    "    company_name = company_details.get('name', 'Company name not found')\n",
    "    company_url = company_details.get('url', 'Company URL not found')\n",
    "\n",
    "    # Structuring the extracted job description details\n",
    "    extracted_job_info = {\n",
    "        'title': job_description.get('title', ''),\n",
    "        'companyName': company_name,\n",
    "        'companyURL': company_url,\n",
    "        'descriptionText': job_description.get('description', {}).get('text', '')\n",
    "    }\n",
    "\n",
    "    return extracted_job_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687a9fa",
   "metadata": {},
   "source": [
    "## Get company data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c83ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def extract_linkedin_company_id(company_url):\n",
    "    \"\"\"\n",
    "    Extracts the LinkedIn company ID (universal name) from a given company URL.\n",
    "    \"\"\"\n",
    "    decoded_url = unquote(company_url)\n",
    "    path = urlparse(decoded_url).path\n",
    "    path_parts = path.strip(\"/\").split(\"/\")\n",
    "    \n",
    "    # Assuming the URL format is https://www.linkedin.com/company/[company-id]/\n",
    "    company_id = path_parts[-1] if path_parts[-2] == 'company' else None\n",
    "    return company_id\n",
    "\n",
    "def linkedin_company_info_extractor(company_url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves detailed information about a company from LinkedIn based on the provided company URL.\n",
    "\n",
    "    This function extracts various pieces of company information, including the company's name, description, staff count,\n",
    "    industry, specialties, and follower count. It first extracts the company ID from the URL, then uses that ID to fetch\n",
    "    and compile detailed company information from LinkedIn's API or a similar data source.\n",
    "\n",
    "    Parameters:\n",
    "    - company_url (str): The URL of the company's LinkedIn page.\n",
    "\n",
    "    Returns:\n",
    "    - company_info (dict): A dictionary containing key information about the company, such as:\n",
    "        - 'name': The name of the company.\n",
    "        - 'description': A brief description of the company.\n",
    "        - 'staffCount': The number of employees at the company.\n",
    "        - 'industry': The primary industry or industries the company operates in.\n",
    "        - 'specialties': A list of the company's specialties or areas of expertise.\n",
    "        - 'followerCount': The number of followers the company has on LinkedIn.\n",
    "\n",
    "    Note:\n",
    "    The function relies on the ability to extract a company ID from the given URL and fetch data from an API or data source\n",
    "    that provides comprehensive company information based on that ID.\n",
    "\n",
    "    Usage:\n",
    "    - This function can be used to gather insights about a company's presence and reputation on LinkedIn, aiding in\n",
    "    market research, competitive analysis, or job search preparation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the LinkedIn company ID from the URL\n",
    "    company_id = extract_linkedin_company_id(company_url)\n",
    "    \n",
    "    company_data = api.get_company(company_id)  \n",
    "    \n",
    "     # Extracting basic company information\n",
    "    company_info = {\n",
    "        'name': company_data.get('name', 'N/A'),\n",
    "        'description': company_data.get('description', ''),\n",
    "        'staffCount': company_data.get('staffCount', 'N/A'),\n",
    "        'industry': ', '.join([industry['localizedName'] for industry in company_data.get('companyIndustries', [])]),\n",
    "        'specialties': company_data.get('specialities', []),\n",
    "        'followerCount': company_data.get('followingInfo', {}).get('followerCount', 'N/A'),\n",
    "    }\n",
    "\n",
    "    return company_info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08321f7e",
   "metadata": {},
   "source": [
    "## Get job description and company combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06caf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_job_company_extractor(job_url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts and combines details of a job description and its associated company information from LinkedIn based on a job URL.\n",
    "\n",
    "    This function performs two main tasks:\n",
    "    1. Extracts job description details from LinkedIn using the given job URL.\n",
    "    2. Extracts the company's information associated with the job using the 'companyURL' found in the job description details.\n",
    "\n",
    "    Parameters:\n",
    "    - job_url (str): The URL of the job posting on LinkedIn.\n",
    "\n",
    "    Returns:\n",
    "    - combined_info (dict): A dictionary containing both the job description details and the company information. The company information is nested under the 'companyInfo' key within the returned dictionary.\n",
    "\n",
    "    Usage:\n",
    "    - To obtain comprehensive details about a job and its posting company on LinkedIn, pass the job posting URL to this function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract job description details\n",
    "    job_description_details = linkedin_job_description_extractor(job_url)\n",
    "    \n",
    "    # Extract 'companyURL' from job description details\n",
    "    company_url = job_description_details['companyURL']\n",
    "    \n",
    "    # Then, use the extracted 'companyURL' to get company information\n",
    "    company_info_details = linkedin_company_info_extractor(company_url)\n",
    "    \n",
    "    # Combine job description details with company information\n",
    "    combined_info = {\n",
    "        **job_description_details,\n",
    "        'companyInfo': company_info_details\n",
    "    }\n",
    "    \n",
    "    return combined_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
